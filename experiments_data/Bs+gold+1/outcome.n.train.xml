<?xml version='1.0' encoding='UTF-8'?>
<corpus lang="en">
  <lexelt item="outcome.n" pos="NN">
    <instance id="br-f23#w1300_0" docsrc="br-f23">
      <context> The evidence suggests that foreign peoples believe the United_States is weaker than the Soviet_Union , and is bound to fall still further behind in the years ahead . This ignorant estimate , I repeat , is not of any interest in itself ; but it becomes very important if foreign peoples react the way human_beings typically do - namely , by taking steps to end_up on what appears to be the winning side . To the extent , then , that declining U._S. prestige means that other nations will be tempted to place their bets on an ultimate American defeat , and will thus be more vulnerable to Soviet intimidation , there is reason for concern . Still , these guesses about the <head>outcome</head> of the struggle cannot be as important as the actual power relationship between the Soviet_Union and ourselves . Here I do not speak_of military power where our advantage is obvious and overwhelming but of political power - of influence , if you will - about which the relevant questions are : Is Soviet influence throughout the world greater or less than it was ten years ago ? And is Western influence greater or less than it used to be ?</context>
    </instance>
    <instance id="br-g11#w832_0" docsrc="br-g11">
      <context> They are in_general those fears that once seemed to have been amenable to prayer or ritual . They include both individual fears and collective ones . They arise in situations in which one believes that what happens depends not_only on the external world , but also on the precise pattern of behavior of the individual or group . Often it is recognized that all the details of the pattern may not be essential to the <head>outcome</head> but , because the pattern was empirically determined and not developed through theoretical understanding , one is never quite certain which behavior elements are effective , and the whole pattern becomes ritualized . Yet often fear persists because , even with the most rigid ritual , one is never quite free from the uneasy feeling that one might make some mistake or that in every previous execution one had been unaware of the really decisive act . To say that science had reduced many such fears merely reiterates the obvious and frequent statement that science eliminated much of magic and superstition . But a somewhat more detailed analysis of this process may be illuminating .</context>
    </instance>
    <instance id="br-j19#w1028_0" docsrc="br-j19">
      <context> `` Success '' and `` failure '' are just convenient labels for the two categories of outcomes when we talk_about binomial trials in_general . These words are more expressive than labels like `` A '' and `` not - A '' . It is natural from the marksman 's viewpoint to call a bull's-eye a success , but in the mice example it is arbitrary which category corresponds to straight hair in a mouse . The word `` binomial '' means `` of two names '' or `` of two terms '' , and both usages apply in our work : the first to the names of the two <head>outcomes</head> of a binomial trial , and the second to the terms p and * * f that represent the probabilities of `` success '' and `` failure '' . Sometimes when there are many outcomes for a single trial , we group these outcomes into two classes , as in the example of the die , where we have arbitrarily constructed the classes `` ace '' and `` not ace '' . We classify mice as `` straight haired '' or `` wavy haired '' , but a hairless mouse appears . We can escape_from such a difficulty by ruling_out the animal as not constituting a trial , but such a solution is not always satisfactory .</context>
    </instance>
    <instance id="br-j19#w1063_0" docsrc="br-j19">
      <context> These words are more expressive than labels like `` A '' and `` not - A '' . It is natural from the marksman 's viewpoint to call a bull's-eye a success , but in the mice example it is arbitrary which category corresponds to straight hair in a mouse . The word `` binomial '' means `` of two names '' or `` of two terms '' , and both usages apply in our work : the first to the names of the two outcomes of a binomial trial , and the second to the terms p and * * f that represent the probabilities of `` success '' and `` failure '' . Sometimes when there are many <head>outcomes</head> for a single trial , we group these outcomes into two classes , as in the example of the die , where we have arbitrarily constructed the classes `` ace '' and `` not ace '' . We classify mice as `` straight haired '' or `` wavy haired '' , but a hairless mouse appears . We can escape_from such a difficulty by ruling_out the animal as not constituting a trial , but such a solution is not always satisfactory . Each die has probability * * f of producing an ace ; the marksman has some probability p , perhaps 0.1 , of making a bull's-eye .</context>
    </instance>
    <instance id="br-j19#w1072_0" docsrc="br-j19">
      <context> These words are more expressive than labels like `` A '' and `` not - A '' . It is natural from the marksman 's viewpoint to call a bull's-eye a success , but in the mice example it is arbitrary which category corresponds to straight hair in a mouse . The word `` binomial '' means `` of two names '' or `` of two terms '' , and both usages apply in our work : the first to the names of the two outcomes of a binomial trial , and the second to the terms p and * * f that represent the probabilities of `` success '' and `` failure '' . Sometimes when there are many outcomes for a single trial , we group these <head>outcomes</head> into two classes , as in the example of the die , where we have arbitrarily constructed the classes `` ace '' and `` not ace '' . We classify mice as `` straight haired '' or `` wavy haired '' , but a hairless mouse appears . We can escape_from such a difficulty by ruling_out the animal as not constituting a trial , but such a solution is not always satisfactory . Each die has probability * * f of producing an ace ; the marksman has some probability p , perhaps 0.1 , of making a bull's-eye .</context>
    </instance>
    <instance id="br-j19#w1225_0" docsrc="br-j19">
      <context> Each die has probability * * f of producing an ace ; the marksman has some probability p , perhaps 0.1 , of making a bull's-eye . Note that we need not know the value of p , for the experiment to be binomial . During a round of target_practice the sun comes from behind a cloud and dazzles the marksman , lowering his chance of a bull's-eye . Strictly_speaking , this means that the probability for each possible <head>outcome</head> of the experiment can be computed by multiplying together the probabilities of the possible outcomes of the single binomial trials . Thus in the three dice example * * f , * * f , and the independence assumption implies that the probability that the three dice fall ace , not ace , ace in that order is ( 1 6 ) ( 5 6 ) ( 1 6 ) . Experimentally , we expect independence when the trials have nothing to do with one another . A family of five plans to go together either to the beach or to the mountains , and a coin is tossed to decide .</context>
    </instance>
    <instance id="br-j19#w1240_0" docsrc="br-j19">
      <context> Each die has probability * * f of producing an ace ; the marksman has some probability p , perhaps 0.1 , of making a bull's-eye . Note that we need not know the value of p , for the experiment to be binomial . During a round of target_practice the sun comes from behind a cloud and dazzles the marksman , lowering his chance of a bull's-eye . Strictly_speaking , this means that the probability for each possible outcome of the experiment can be computed by multiplying together the probabilities of the possible <head>outcomes</head> of the single binomial trials . Thus in the three dice example * * f , * * f , and the independence assumption implies that the probability that the three dice fall ace , not ace , ace in that order is ( 1 6 ) ( 5 6 ) ( 1 6 ) . Experimentally , we expect independence when the trials have nothing to do with one another . A family of five plans to go together either to the beach or to the mountains , and a coin is tossed to decide .</context>
    </instance>
    <instance id="br-j19#w1370_0" docsrc="br-j19">
      <context> Experimentally , we expect independence when the trials have nothing to do with one another . A family of five plans to go together either to the beach or to the mountains , and a coin is tossed to decide . We want to know the number of people going_to the mountains . When this experiment is viewed_as composed of five binomial trials , one for each member of the family , the <head>outcomes</head> of the trials are obviously not independent . Indeed , the experiment is better viewed_as consisting_of one binomial trial for the entire family . The following is a less extreme example of dependence . Consider couples visiting an art museum .</context>
    </instance>
    <instance id="br-j19#w14_0" docsrc="br-j19">
      <context> Some experiments are composed of repetitions of independent trials , each with two possible <head>outcomes</head> . The binomial probability distribution may describe the variation that occurs from one set of trials of such a binomial experiment to another . We devote a chapter to the binomial_distribution not_only because it is a mathematical model for an enormous variety of real_life phenomena , but also because it has important properties that recur in many other probability models . We begin with a_few examples of binomial experiments .</context>
    </instance>
    <instance id="br-j19#w174_0" docsrc="br-j19">
      <context> In repeated sets of five shots his numbers of bull's-eyes vary . What can we say of the probabilities of the different possible numbers of bull's-eyes ? In litters of eight mice from similar parents , the number of mice with straight instead of wavy hair is an integer from 0 to 8 . What probabilities should be attached to these possible <head>outcomes</head> ? When three dice are tossed repeatedly , what is the probability that the number of aces is 0 ( or 1 , or 2 , or 3 ) ? More generally , suppose that an experiment consists_of a number of independent trials , that each trial results in either a `` success '' or a `` non success '' ( `` failure '' ) , and that the probability of success remains constant from trial to trial . In the examples above , the occurrence of a bull's-eye , a straight haired mouse , or an ace could be called a `` success '' .</context>
    </instance>
    <instance id="br-j19#w1883_0" docsrc="br-j19">
      <context> ( For_instance , see Example 2 of Section 5 - 5 , on red cards in hands of 5 . ) On_the_other_hand , even when the binomial model does not describe well the physical_phenomenon being studied , the binomial model may still be used as a baseline for comparative purposes ; that_is , we may discuss the phenomenon in_terms_of its departures from the binomial model . A binomial experiment consists_of * * f independent binomial trials , all with the same probability * * f of yielding a success . The <head>outcome</head> of the experiment is X successes . The random_variable X takes the values * * f with probabilities * * f or , more briefly * * f . We shall find a formula for the probability of exactly x successes for given values of p and n . When each number of successes x is paired with its probability of occurrence * * f , the set of pairs * * f , is a probability function called a binomial_distribution .</context>
    </instance>
    <instance id="br-j19#w284_0" docsrc="br-j19">
      <context> When three dice are tossed repeatedly , what is the probability that the number of aces is 0 ( or 1 , or 2 , or 3 ) ? More generally , suppose that an experiment consists_of a number of independent trials , that each trial results in either a `` success '' or a `` non success '' ( `` failure '' ) , and that the probability of success remains constant from trial to trial . In the examples above , the occurrence of a bull's-eye , a straight haired mouse , or an ace could be called a `` success '' . In_general , any <head>outcome</head> we choose may be labeled `` success '' . The major question in this chapter is : What is the probability of exactly x successes in n trials ? In Chapters 3 and 4 we answered questions like those in the examples , usually by counting points in a sample space . Fortunately , a general formula of wide applicability solves all problems of this kind .</context>
    </instance>
    <instance id="br-j19#w403_0" docsrc="br-j19">
      <context> Fortunately , a general formula of wide applicability solves all problems of this kind . Before deriving this formula , we explain what we mean by `` problems of this kind '' . Experiments are often composed of several identical trials , and sometimes experiments themselves are repeated . In the marksmanship example , a trial consists_of `` one round shot at a target '' with <head>outcome</head> either one bull's-eye ( success ) or none ( failure ) . Further , an experiment might consist_of five rounds , and several sets of five rounds might be regarded_as a super experiment composed of several repetitions of the five round experiment . If three dice are tossed , a trial is one toss of one die and the experiment is composed of three trials . Or , what amounts to the same thing , if one die is tossed three times , each toss is a trial , and the three tosses form the experiment .</context>
    </instance>
    <instance id="br-j19#w663_0" docsrc="br-j19">
      <context> 0 time ? Note that there are 3 trials of interest . Each trial consists_of choosing a student manager at_random . The 2 possible <head>outcomes</head> on each trial are `` driver '' or `` nondriver '' . Since the choice is by lot each_week , the outcomes of different trials are independent . The managers stay the same , so that * * f is the same for all weeks . We now generalize these ideas for general binomial experiments .</context>
    </instance>
    <instance id="br-j19#w685_0" docsrc="br-j19">
      <context> Note that there are 3 trials of interest . Each trial consists_of choosing a student manager at_random . The 2 possible outcomes on each trial are `` driver '' or `` nondriver '' . Since the choice is by lot each_week , the <head>outcomes</head> of different trials are independent . The managers stay the same , so that * * f is the same for all weeks . We now generalize these ideas for general binomial experiments . For an experiment to qualify as a binomial experiment , it must have four properties : ( 1 ) there must be a fixed number of trials , ( 2 ) each trial must result in a `` success '' or a `` failure '' ( a binomial trial ) , ( 3 ) all trials must have identical probabilities of success , ( 4 ) the trials must be independent of each other .</context>
    </instance>
    <instance id="br-j19#w935_0" docsrc="br-j19">
      <context> Toss a die until an ace appears . Here the number of trials is a random_variable , not a fixed number . Each of the n trials is either a success or a failure . `` Success '' and `` failure '' are just convenient labels for the two categories of <head>outcomes</head> when we talk_about binomial trials in_general . These words are more expressive than labels like `` A '' and `` not - A '' . It is natural from the marksman 's viewpoint to call a bull's-eye a success , but in the mice example it is arbitrary which category corresponds to straight hair in a mouse . The word `` binomial '' means `` of two names '' or `` of two terms '' , and both usages apply in our work : the first to the names of the two outcomes of a binomial trial , and the second to the terms p and * * f that represent the probabilities of `` success '' and `` failure '' .</context>
    </instance>
    <instance id="br-j35#w1558_0" docsrc="br-j35">
      <context> These findings , and_others which will in_time be developed , will affect the method of glottochronological inquiry . If adjectival meanings show relatively low retentiveness of stems , as I am confident will prove to be the case in most languages of the world , why should our basic lists include 15 per_cent of these unstable forms , but only 8 per_cent of animals and plants which replace much more slowly ? Had Hoijer substituted for his 15 adjectival slots 15 good animal and plant items , his rate of stem replacement would have been lower and the age of Athabascan language separation smaller . And irrespective of the <head>outcome</head> in centuries elapsed since splitting , calculations obviously carry more concordant and comparable meaning if they deal with the most stable units than with variously unstable ones . It is evident that Swadesh has not_only had much experience with basic vocabulary in many languages but has acquired great tact and feeling for the expectable behavior of lexical items . Why then this urge to include unstable items in his basic list ? It is the urge to obtain a list as free_of geographical and cultural conditioning as possible .</context>
    </instance>
    <instance id="br-k27#w1961_0" docsrc="br-k27">
      <context> The events of the last quarter of an hour , mysterious to any bird accustomed only to the predictable life of coop and barnyard , had overcome the doctor 's hen and she gave_out a series of cackly wails , perhaps mourning her nest , but briefly enjoyed . The doctor 's wits had not left him , however , for all his sixty-eight years , and the wails were almost immediately lost in the sound of water rushing_out from the showerhead . Alex nodded to the maid as though nothing unusual were taking_place and entered the doctor 's room . Shortly , the doctor himself entered , his hair somewhat wet from the shower , but evidently satisfied with the <head>outcome</head> of their adventures . Without comment he opened the closet and from its shelves constructed a highboard around the egg case which he had placed on the floor inside . Next , the hen was nested and all seemed well . The two men sat for some time , savoring the pleasure of escape from peril and the relief such escape brings , before they got_up and left the hotel , the doctor to go_to the conference_house and Alex to go_to the main post_office .</context>
    </instance>
  </lexelt>
</corpus>
